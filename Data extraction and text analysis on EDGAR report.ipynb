{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction and Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('cik_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt   \n",
       "\n",
       "                                              Source  \n",
       "0  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "1  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "2  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "3  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "4  https://www.sec.gov/Archives/edgar/data/3662/0...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_dictionaryFile = 'uncertainty_dictionary.txt'\n",
    "constraining_dictionaryFile = 'constraining_dictionary.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsFile = 'StopWords_Generic.txt'\n",
    "positiveWordsFile = 'PositiveWords.txt'\n",
    "negitiveWordsFile = 'NegativeWords.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Stop words\n",
    "with open(stopWordsFile ,'r') as stop_words:\n",
    "    stopWords = stop_words.read().lower()\n",
    "stopWordList = stopWords.split('\\n')\n",
    "stopWordList[-1:] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading positive words\n",
    "with open(positiveWordsFile,'r') as posfile:\n",
    "    positivewords=posfile.read().lower()\n",
    "positiveWordList=positivewords.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading negative words\n",
    "with open(negitiveWordsFile ,'r') as negfile:\n",
    "    negativeword=negfile.read().lower()\n",
    "negativeWordList=negativeword.split('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.1 Positive score, Negative score and polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating positive score \n",
    "def positive_score(text):\n",
    "    numPosWords = 0\n",
    "    rawToken = tokenizer(text)\n",
    "    for word in rawToken:\n",
    "        if word in positiveWordList:\n",
    "            numPosWords  += 1\n",
    "    \n",
    "    sumPos = numPosWords\n",
    "    return sumPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Negative score\n",
    "def negative_score(text):\n",
    "    numNegWords=0\n",
    "    rawToken = tokenizer(text)\n",
    "    for word in rawToken:\n",
    "        if word in negativeWordList:\n",
    "            numNegWords -=1\n",
    "    sumNeg = numNegWords \n",
    "    sumNeg = sumNeg * -1\n",
    "    return sumNeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating polarity score\n",
    "def polarity_score(positiveScore, negativeScore):\n",
    "    pol_score = (positiveScore - negativeScore) / ((positiveScore + negativeScore) + 0.000001)\n",
    "    return pol_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Average sentance length, percentage of complex words, fog index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_words = list(filter(lambda token: token not in stopWordList, tokens))\n",
    "    return filtered_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sentence_length(text):\n",
    "    sentence_list = sent_tokenize(text)\n",
    "    tokens = tokenizer(text)\n",
    "    totalWordCount = len(tokens)\n",
    "    totalSentences = len(sentence_list)\n",
    "    average_sent = 0\n",
    "    if totalSentences != 0:\n",
    "        average_sent = totalWordCount / totalSentences\n",
    "    \n",
    "    average_sent_length= average_sent\n",
    "    \n",
    "    return round(average_sent_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating percentage of complex word \n",
    "# It is calculated using Percentage of Complex words = the number of complex words / the number of words \n",
    "\n",
    "def percentage_complex_word(text):\n",
    "    tokens = tokenizer(text)\n",
    "    complexWord = 0\n",
    "    complex_word_percentage = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        vowels=0\n",
    "        if word.endswith(('es','ed')):\n",
    "            pass\n",
    "        else:\n",
    "            for w in word:\n",
    "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                    vowels += 1\n",
    "            if(vowels > 2):\n",
    "                complexWord += 1\n",
    "    if len(tokens) != 0:\n",
    "        complex_word_percentage = complexWord/len(tokens)\n",
    "    \n",
    "    return complex_word_percentage\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Fog Index \n",
    "# Fog index is calculated using -- Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "\n",
    "def fog_index(averageSentenceLength, percentageComplexWord):\n",
    "    fogIndex = 0.4 * (averageSentenceLength + percentageComplexWord)\n",
    "    return fogIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Complex word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_word_count(text):\n",
    "    tokens = tokenizer(text)\n",
    "    complexWord = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        vowels=0\n",
    "        if word.endswith(('es','ed')):\n",
    "            pass\n",
    "        else:\n",
    "            for w in word:\n",
    "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                    vowels += 1\n",
    "            if(vowels > 2):\n",
    "                complexWord += 1\n",
    "    return complexWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting total words\n",
    "\n",
    "def total_word_count(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return len(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  uncertainty and constraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating uncertainty_score\n",
    "with open(uncertainty_dictionaryFile ,'r') as uncertain_dict:\n",
    "    uncertainDict=uncertain_dict.read().lower()\n",
    "uncertainDictionary = uncertainDict.split('\\n')\n",
    "\n",
    "def uncertainty_score(text):\n",
    "    uncertainWordnum =0\n",
    "    rawToken = tokenizer(text)\n",
    "    for word in rawToken:\n",
    "        if word in uncertainDictionary:\n",
    "            uncertainWordnum +=1\n",
    "    sumUncertainityScore = uncertainWordnum \n",
    "    \n",
    "    return sumUncertainityScore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating constraining score\n",
    "with open(constraining_dictionaryFile ,'r') as constraining_dict:\n",
    "    constrainDict=constraining_dict.read().lower()\n",
    "constrainDictionary = constrainDict.split('\\n')\n",
    "\n",
    "def constraining_score(text):\n",
    "    constrainWordnum =0\n",
    "    rawToken = tokenizer(text)\n",
    "    for word in rawToken:\n",
    "        if word in constrainDictionary:\n",
    "            constrainWordnum +=1\n",
    "    sumConstrainScore = constrainWordnum \n",
    "    \n",
    "    return sumConstrainScore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  positive/negative and uncertainty/constraining word proportion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating positive word proportion\n",
    "\n",
    "def positive_word_prop(positiveScore,wordcount):\n",
    "    positive_word_proportion = 0\n",
    "    if wordcount !=0:\n",
    "        positive_word_proportion = positiveScore / wordcount\n",
    "        \n",
    "    return positive_word_proportion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating negative word proportion\n",
    "\n",
    "def negative_word_prop(negativeScore,wordcount):\n",
    "    negative_word_proportion = 0\n",
    "    if wordcount !=0:\n",
    "        negative_word_proportion = negativeScore / wordcount\n",
    "        \n",
    "    return negative_word_proportion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating uncertain word proportion\n",
    "\n",
    "def uncertain_word_prop(uncertainScore,wordcount):\n",
    "    uncertain_word_proportion = 0\n",
    "    if wordcount !=0:\n",
    "        uncertain_word_proportion = uncertainScore / wordcount\n",
    "        \n",
    "    return uncertain_word_proportion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating constraining word proportion\n",
    "\n",
    "def constraining_word_prop(constrainingScore,wordcount):\n",
    "    constraining_word_proportion = 0\n",
    "    if wordcount !=0:\n",
    "        constraining_word_proportion = constrainingScore / wordcount\n",
    "        \n",
    "    return constraining_word_proportion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraining words for whole report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Constraining words for whole report\n",
    "\n",
    "def constrain_word_whole(mdaText,qqdmrText,rfText):\n",
    "    wholeDoc = mdaText + qqdmrText + rfText\n",
    "    constrainWordnumWhole =0\n",
    "    rawToken = tokenizer(wholeDoc)\n",
    "    for word in rawToken:\n",
    "        if word in constrainDictionary:\n",
    "            constrainWordnumWhole +=1\n",
    "    sumConstrainScoreWhole = constrainWordnumWhole \n",
    "    \n",
    "    return sumConstrainScoreWhole\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_r(link):\n",
    "    response = requests.get(link)\n",
    "    data = response.text\n",
    "    data = re.sub('\\n', ' ', data)\n",
    "    data = re.sub('\\t', ' ', data)\n",
    "    data = re.sub('[\\-=]', '', data)\n",
    "    data = re.sub(' +', ' ', data)\n",
    "    data = re.sub('\\.+','.',data)\n",
    "    z=re.findall(r\"item[^a-zA-Z\\n]*\\d*Risk Factors *[^=]*?item \\d\", data, re.M|re.I)\n",
    "\n",
    "    l3 = len(z) \n",
    "    \n",
    "    if l3==0:\n",
    "        risk = ''\n",
    "    else:\n",
    "        risk =z[l3-1] \n",
    "    \n",
    "    return risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_m(link):\n",
    "    response = requests.get(link)\n",
    "    data = response.text\n",
    "    data = re.sub('\\n', ' ', data)\n",
    "    data = re.sub('\\t', ' ', data)\n",
    "    data = re.sub('[\\-=]', '', data)\n",
    "    data = re.sub(' +', ' ', data)\n",
    "    data = re.sub('\\.+','.',data)\n",
    "    x=re.findall( r\"item[^a-zA-Z\\n]*\\d*management\\'s discussion and analysis *[^=]*?item \\d\", data, re.M|re.I)\n",
    "    l1 = len(x)\n",
    "\n",
    "   \n",
    "    if l1==0:\n",
    "        management = ''\n",
    "    else:\n",
    "        management = x[l1-1]\n",
    "\n",
    "    \n",
    "    return management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_q(link):\n",
    "    response = requests.get(link)\n",
    "    data = response.text\n",
    "    data = re.sub('\\n', ' ', data)\n",
    "    data = re.sub('\\t', ' ', data)\n",
    "    data = re.sub('[\\-=]', '', data)\n",
    "    data = re.sub(' +', ' ', data)\n",
    "    data = re.sub('\\.+','.',data)\n",
    "    y=re.findall(r\"item[^a-zA-Z\\n]*\\d*Quantitative and Qualitative Disclosures about Market Risk *[^=]*?item \\d\", data, re.M|re.I)\n",
    "\n",
    "    l2 = len(y)\n",
    "\n",
    "    if l2==0:\n",
    "        Quantitative = ''\n",
    "    else:\n",
    "        Quantitative = y[l2-1]\n",
    "\n",
    "    \n",
    "    return Quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mda_extract'] = df.Source.apply(data_processing_m)\n",
    "df['qqd_extract'] = df.Source.apply(data_processing_q)\n",
    "df['riskfactor_extract'] = df.Source.apply(data_processing_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mda_positive_score'] = df.mda_extract.apply(positive_score)\n",
    "df['mda_negative_score'] = df.mda_extract.apply(negative_score)\n",
    "df['mda_polarity_score'] = np.vectorize(polarity_score)(df['mda_positive_score'],df['mda_negative_score'])\n",
    "df['mda_average_sentence_length'] = df.mda_extract.apply(average_sentence_length)\n",
    "df['mda_percentage_of_complex_words'] = df.mda_extract.apply(percentage_complex_word)\n",
    "df['mda_fog_index'] = np.vectorize(fog_index)(df['mda_average_sentence_length'],df['mda_percentage_of_complex_words'])\n",
    "df['mda_complex_word_count']= df.mda_extract.apply(complex_word_count)\n",
    "df['mda_word_count'] = df.mda_extract.apply(total_word_count)\n",
    "df['mda_uncertainty_score']=df.mda_extract.apply(uncertainty_score)\n",
    "df['mda_constraining_score'] = df.mda_extract.apply(constraining_score)\n",
    "df['mda_positive_word_proportion'] = np.vectorize(positive_word_prop)(df['mda_positive_score'],df['mda_word_count'])\n",
    "df['mda_negative_word_proportion'] = np.vectorize(negative_word_prop)(df['mda_negative_score'],df['mda_word_count'])\n",
    "df['mda_uncertainty_word_proportion'] = np.vectorize(uncertain_word_prop)(df['mda_uncertainty_score'],df['mda_word_count'])\n",
    "df['mda_constraining_word_proportion'] = np.vectorize(constraining_word_prop)(df['mda_constraining_score'],df['mda_word_count'])\n",
    "\n",
    "df['qqdmr_positive_score'] = df.qqd_extract.apply(positive_score)\n",
    "df['qqdmr_negative_score'] = df.qqd_extract.apply(negative_score)\n",
    "df['qqdmr_polarity_score'] = np.vectorize(polarity_score)(df['qqdmr_positive_score'],df['qqdmr_negative_score'])\n",
    "df['qqdmr_average_sentence_length'] = df.qqd_extract.apply(average_sentence_length)\n",
    "df['qqdmr_percentage_of_complex_words'] = df.qqd_extract.apply(percentage_complex_word)\n",
    "df['qqdmr_fog_index'] = np.vectorize(fog_index)(df['qqdmr_average_sentence_length'],df['qqdmr_percentage_of_complex_words'])\n",
    "df['qqdmr_complex_word_count']= df.qqd_extract.apply(complex_word_count)\n",
    "df['qqdmr_word_count'] = df.qqd_extract.apply(total_word_count)\n",
    "df['qqdmr_uncertainty_score']=df.qqd_extract.apply(uncertainty_score)\n",
    "df['qqdmr_constraining_score'] = df.qqd_extract.apply(constraining_score)\n",
    "df['qqdmr_positive_word_proportion'] = np.vectorize(positive_word_prop)(df['qqdmr_positive_score'],df['qqdmr_word_count'])\n",
    "df['qqdmr_negative_word_proportion'] = np.vectorize(negative_word_prop)(df['qqdmr_negative_score'],df['qqdmr_word_count'])\n",
    "df['qqdmr_uncertainty_word_proportion'] = np.vectorize(uncertain_word_prop)(df['qqdmr_uncertainty_score'],df['qqdmr_word_count'])\n",
    "df['qqdmr_constraining_word_proportion'] = np.vectorize(constraining_word_prop)(df['qqdmr_constraining_score'],df['qqdmr_word_count'])\n",
    "\n",
    "df['rf_positive_score'] = df.riskfactor_extract.apply(positive_score)\n",
    "df['rf_negative_score'] = df.riskfactor_extract.apply(negative_score)\n",
    "df['rf_polarity_score'] = np.vectorize(polarity_score)(df['rf_positive_score'],df['rf_negative_score'])\n",
    "df['rf_average_sentence_length'] = df.riskfactor_extract.apply(average_sentence_length)\n",
    "df['rf_percentage_of_complex_words'] = df.riskfactor_extract.apply(percentage_complex_word)\n",
    "df['rf_fog_index'] = np.vectorize(fog_index)(df['rf_average_sentence_length'],df['rf_percentage_of_complex_words'])\n",
    "df['rf_complex_word_count']= df.riskfactor_extract.apply(complex_word_count)\n",
    "df['rf_word_count'] = df.riskfactor_extract.apply(total_word_count)\n",
    "df['rf_uncertainty_score']=df.riskfactor_extract.apply(uncertainty_score)\n",
    "df['rf_constraining_score'] = df.riskfactor_extract.apply(constraining_score)\n",
    "df['rf_positive_word_proportion'] = np.vectorize(positive_word_prop)(df['rf_positive_score'],df['rf_word_count'])\n",
    "df['rf_negative_word_proportion'] = np.vectorize(negative_word_prop)(df['rf_negative_score'],df['rf_word_count'])\n",
    "df['rf_uncertainty_word_proportion'] = np.vectorize(uncertain_word_prop)(df['rf_uncertainty_score'],df['rf_word_count'])\n",
    "df['rf_constraining_word_proportion'] = np.vectorize(constraining_word_prop)(df['rf_constraining_score'],df['rf_word_count'])\n",
    "\n",
    "df['constraining_words_whole_report'] = np.vectorize(constrain_word_whole)(df['mda_extract'],df['qqd_extract'],df['riskfactor_extract'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>Source</th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>mda_negative_score</th>\n",
       "      <th>mda_polarity_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rf_fog_index</th>\n",
       "      <th>rf_complex_word_count</th>\n",
       "      <th>rf_word_count</th>\n",
       "      <th>rf_uncertainty_score</th>\n",
       "      <th>rf_constraining_score</th>\n",
       "      <th>rf_positive_word_proportion</th>\n",
       "      <th>rf_negative_word_proportion</th>\n",
       "      <th>rf_uncertainty_word_proportion</th>\n",
       "      <th>rf_constraining_word_proportion</th>\n",
       "      <th>constraining_words_whole_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>20</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.574468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.661538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>32</td>\n",
       "      <td>118</td>\n",
       "      <td>-0.573333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt   \n",
       "\n",
       "                                              Source  mda_positive_score  \\\n",
       "0  https://www.sec.gov/Archives/edgar/data/3662/0...                  20   \n",
       "1  https://www.sec.gov/Archives/edgar/data/3662/0...                  11   \n",
       "2  https://www.sec.gov/Archives/edgar/data/3662/0...                   0   \n",
       "3  https://www.sec.gov/Archives/edgar/data/3662/0...                  32   \n",
       "4  https://www.sec.gov/Archives/edgar/data/3662/0...                   0   \n",
       "\n",
       "   mda_negative_score  mda_polarity_score  ...  rf_fog_index  \\\n",
       "0                  74           -0.574468  ...           0.0   \n",
       "1                  54           -0.661538  ...           0.0   \n",
       "2                   0            0.000000  ...           0.0   \n",
       "3                 118           -0.573333  ...           0.0   \n",
       "4                   0            0.000000  ...           0.0   \n",
       "\n",
       "   rf_complex_word_count  rf_word_count  rf_uncertainty_score  \\\n",
       "0                      0              0                     0   \n",
       "1                      0              0                     0   \n",
       "2                      0              0                     0   \n",
       "3                      0              0                     0   \n",
       "4                      0              0                     0   \n",
       "\n",
       "   rf_constraining_score  rf_positive_word_proportion  \\\n",
       "0                      0                            0   \n",
       "1                      0                            0   \n",
       "2                      0                            0   \n",
       "3                      0                            0   \n",
       "4                      0                            0   \n",
       "\n",
       "   rf_negative_word_proportion  rf_uncertainty_word_proportion  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "\n",
       "   rf_constraining_word_proportion  constraining_words_whole_report  \n",
       "0                                0                               11  \n",
       "1                                0                                3  \n",
       "2                                0                                0  \n",
       "3                                0                               26  \n",
       "4                                0                                0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputTextCol = ['mda_extract','qqd_extract','riskfactor_extract']\n",
    "finalOutput = df.drop(inputTextCol,1)\n",
    "\n",
    "finalOutput.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalOutput.to_csv('textAnalysisOutput.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
